{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Model: Five-Layer Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the simplicity of the network, we decided to replicate their exercise of reproducing the results of Kim et al\n",
    "\n",
    "    B.-K. Kim, S.-Y. Dong, J. Roh, G. Kim, and S.-Y. Lee, “Fusing Aligned and Non-Aligned Face Information for Automatic Affect Recognition in the Wild: A Deep Learning Approach,” in IEEE Conf. Computer Vision and Pattern Recognition (CVPR) Workshops, 2016, pp. 48–57."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model consists of three stages of convolutional and max-pooling layers, followed by an FC layer of size 1024 and a softmax output layer. \n",
    "\n",
    "The convolutional layers use 32, 32, and 64 filters of size 5x5, 4x4, and 5x5, respectively. The max-pooling layers use kernels of size 3x3 and stride 2. ReLU was utilized as the activation function. To improve performance, we also added batchnorm at every layer and 30% dropout after the last FC layer. To fine tune the model, we trained it for 300 epochs, optimizing the cross-entropy loss using stochastic gradient descent with a momentum of 0.9. The initial learning rate, batch size, and weight decay are fixed at 0.1, 128, and 0.0001, respectively. \n",
    "\n",
    "The learning rate is halved if the validation accuracy does not improve for 10 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b> The architecture of neural network </b></p>\n",
    "<img src=\"Architecture_NN.jpg\" alt=\" The architecture of neural network\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we use **Test-Time Augmentation(TTA)** with horizontal flip and seven augmented images to improve the test accuracy of our five-layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing successfully!\n",
      "tensorflow 2.3.0\n",
      "keras 2.4.0\n",
      "GPU [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.lib.io import file_io\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from seaborn import heatmap # seaborn: statistical data visualization\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print('Importing successfully!')\n",
    "print('tensorflow',tf.__version__)\n",
    "print('keras',keras.__version__)\n",
    "print('GPU',tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 128 # batch size,batch size = 128\n",
    "\n",
    "def get_datagen(dataset_path, BS = 128, aug=False):\n",
    "    if aug:\n",
    "        datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                            rescale=1./255,\n",
    "                            featurewise_center=False,\n",
    "                            featurewise_std_normalization=False,\n",
    "                            rotation_range=10,\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1,\n",
    "                            zoom_range=0.1,\n",
    "                            horizontal_flip=True)\n",
    "    else:\n",
    "        datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    return datagen.flow_from_directory(\n",
    "            dataset_path,\n",
    "            target_size =(48, 48),\n",
    "            color_mode ='grayscale',\n",
    "            shuffle = True,\n",
    "            class_mode = 'categorical',\n",
    "            batch_size = BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29902 images belonging to 7 classes.\n",
      "Found 3589 images belonging to 7 classes.\n",
      "Found 3589 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator  = get_datagen(\"/usr/users/gpupro/gprcsr1_1/Desktop/ST7_FER_Projet/FER_Dataset/train\", True)\n",
    "dev_generator    = get_datagen(\"/usr/users/gpupro/gprcsr1_1/Desktop/ST7_FER_Projet/FER_Dataset/test-private\")\n",
    "test_generator  = get_datagen(\"/usr/users/gpupro/gprcsr1_1/Desktop/ST7_FER_Projet/FER_Dataset/test-public\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dropout_rate = 0.3\n",
    "SGD_lr = 0.1 # learning rate of SGD optimiser\n",
    "SGD_decay = 0.0001 #decay of SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(BatchNormalization(input_shape=(48,48,1)))\n",
    "\n",
    "model.add(Conv2D(32, (5, 5), activation='relu',padding='same',name=\"conv1\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3, 3),name=\"maxpool2\"))         \n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(32, (4, 4), activation='relu',padding='same',name=\"conv2\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3, 3),name=\"maxpool3\"))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (5, 5), activation='relu',padding='same',name=\"conv3\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3, 3),name=\"maxpool4\"))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu',name='fc1'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(7, activation='softmax',name='fc2_softmax'))\n",
    "model.add(Dropout(Dropout_rate))\n",
    "model.add(BatchNormalization())\n",
    " \n",
    "sgd = tf.keras.optimizers.SGD(lr=SGD_lr, momentum=0.9, decay=SGD_decay, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More information about **keras.model**, please refer to the [official tutorial](https://www.tensorflow.org/api_docs/python/tf/keras/Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "29900/29902 [============================>.] - ETA: 0s - loss: 1.1921e-07 - accuracy: 0.1376\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.13681, saving model to Baseline-weights-best.hdf5\n",
      "29902/29902 [==============================] - 227s 8ms/step - loss: 1.1921e-07 - accuracy: 0.1376 - val_loss: 1.1921e-07 - val_accuracy: 0.1368\n",
      "Epoch 2/300\n",
      "29901/29902 [============================>.] - ETA: 0s - loss: 1.1921e-07 - accuracy: 0.1376\n",
      "Epoch 00002: val_accuracy did not improve from 0.13681\n",
      "29902/29902 [==============================] - 225s 8ms/step - loss: 1.1921e-07 - accuracy: 0.1376 - val_loss: 1.1921e-07 - val_accuracy: 0.1368\n",
      "Epoch 3/300\n",
      "12483/29902 [===========>..................] - ETA: 2:08 - loss: 1.1921e-07 - accuracy: 0.1398"
     ]
    }
   ],
   "source": [
    "Epochs = 300\n",
    "\n",
    "#  The learning rate is halved if the validation accuracy does not improve for 10 epochs.\n",
    "rlrop = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy',factor=0.5, patience=10, min_lr=0.00001,mode='max')\n",
    "# define the checkpoint\n",
    "cp_filepath='Basic-weights-best.hdf5'\n",
    "checkpoint = ModelCheckpoint(cp_filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "hist = model.fit_generator(\n",
    "    generator = train_generator,\n",
    "    validation_data=dev_generator, \n",
    "    #steps_per_epoch=28709// BS,\n",
    "    #validation_steps=3509 // BS,\n",
    "    shuffle=True,\n",
    "    epochs=Epochs,\n",
    "    callbacks=[rlrop,checkpoint],\n",
    "    use_multiprocessing=False,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('the keys of the trained model:','\\n', hist.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    evaluate_generator(\n",
    "        generator, steps=None, callbacks=None, max_queue_size=10, workers=1,\n",
    "        use_multiprocessing=False, verbose=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n# Evaluate on dev data')\n",
    "results_dev = model.evaluate_generator(dev_generator, 3509 // BS)\n",
    "print('dev loss, dev acc:', results_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n# Evaluate on test data')\n",
    "results_test = model.evaluate_generator(test_generator, 3509 // BS)\n",
    "print('test loss, test acc:', results_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(hist.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'dev'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'dev'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model in the folder *trained_models*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_str = '-EPOCHS_' + str(Epochs)\n",
    "dropout_str = '-DROPOUT_' + str(Dropout_rate)\n",
    "test_acc = '-test_acc_%.3f' % results_test[1]\n",
    "model.save('trained_models/' + 'Basic' + epoch_str + dropout_str + test_acc + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = {0:'Angry', 1:'Disgust', 2:'Fear', 3:'Happy', 4:'Sad', 5:'Surprise', 6:'Neutral'}\n",
    "\n",
    "y_pred = model.predict(dev_generator).argmax(axis=1)\n",
    "y_true = dev_generator.classes\n",
    "\n",
    "cmat_df_test=pd.DataFrame(\n",
    "  confusion_matrix(y_true, y_pred, normalize='true').round(2),\n",
    "  index=emotions.values(), \n",
    "  columns=emotions.values()\n",
    "  )\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "heatmap(cmat_df_test,annot=True,cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion Matrix on Private Test Set')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TTA method \n",
    "We use Test-Time Augmentation(TTA) with horizontal flip and seven augmented images to improve the test accuracy of our five-layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = ?\n",
    "Y_test = ?\n",
    "print('\\n# Evaluate on test data')\n",
    "TTA_results_test = utils tta_evaluate_model(model, X_test, Y_test)\n",
    "print('test loss, test acc:', results_test)\n",
    "print('TTA test acc:', TTA_results_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.3",
   "language": "python",
   "name": "ddsp0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
