{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Models\n",
    "\n",
    "We performed ensembling with soft voting of seven models to significantly improve our highest test accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.python.lib.io import file_io\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import plot_model\n",
    "from sklearn.metrics import *\n",
    "from keras.engine import Model\n",
    "from keras.layers import Input, Flatten, Dense, Activation, Conv2D, MaxPool2D, BatchNormalization, Dropout, MaxPooling2D\n",
    "\n",
    "import skimage\n",
    "from skimage.transform import rescale, resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "print('Importing successfully!')\n",
    "print('tensorflow',tf.__version__)\n",
    "print('tensorflow.keras',tf.keras.__version__)\n",
    "print('keras',keras.__version__)\n",
    "print('GPU',tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Resize_pixelsize = 197"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that reads the data from the csv file, increases the size of the images and returns the images and their labels\n",
    "def get_data(dataset_path, Resize_pixelsize = 197):\n",
    "    \n",
    "    file_stream = file_io.FileIO(dataset_path, mode='r')\n",
    "    data = pd.read_csv(file_stream)\n",
    "    data['pixels'] = data['pixels'].apply(lambda x: [int(pixel) for pixel in x.split()])\n",
    "    X, Y = data['pixels'].tolist(), data['emotion'].values\n",
    "    X = np.array(X, dtype='float32').reshape(-1,48,48,1)\n",
    "    X = X/255.0\n",
    "   \n",
    "    X_res = np.zeros((X.shape[0], Resize_pixelsize,Resize_pixelsize,3))\n",
    "    for ind in range(X.shape[0]): \n",
    "        sample = X[ind]\n",
    "        sample = sample.reshape(48, 48)\n",
    "        image_resized = resize(sample, (Resize_pixelsize, Resize_pixelsize), anti_aliasing=True)\n",
    "        X_res[ind,:,:,:] = image_resized.reshape(Resize_pixelsize,Resize_pixelsize,1)\n",
    "\n",
    "    Y_res = np.zeros((Y.size, 7))\n",
    "    Y_res[np.arange(Y.size),Y] = 1    \n",
    "    \n",
    "    return  X, X_res, Y_res\n",
    "\n",
    "dev_dataset_dir = '/usr/users/gpupro/gprcsr1_1/Desktop/ST7_FER_Projet/FER_Dataset/csv/dev.csv'\n",
    "test_dataset_dir = '/usr/users/gpupro/gprcsr1_1/Desktop/ST7_FER_Projet/FER_Dataset/csv/test.csv'\n",
    "\n",
    "print('Getting data. It may take a few minutes')\n",
    "X_dev, X_res_dev, Y_dev   = get_data(dev_dataset_dir)\n",
    "X_test, X_res_test, Y_test   = get_data(test_dataset_dir)\n",
    "print('Import dataset successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model('/usr/users/gpupro/gprcsr1_1/Desktop/ST7_FER_Projet/cs230-fer/soa-SGD_LR_0.01000-EPOCHS_300-BS_128-DROPOUT_0.3test_acc_0.663.h5')\n",
    "model2 = load_model('/usr/users/gpupro/gprcsr1_1/Desktop/ST7_FER_Projet/cs230-fer/soa-SGD_LR_0.01000-EPOCHS_300-BS_128-DROPOUT_0.4test_acc_0.657.h5')\n",
    "\n",
    "Resnet_model = load_model('/usr/users/gpupro/gprcsr1_1/Desktop/ST7_FER_Projet/cs230-fer/ResNet-BEST-73.2.h5')\n",
    "Resnet_Aux_model_wcw = load_model(\"/usr/users/gpupro/gprcsr1_1/Desktop/ST7_FER_Projet/cs230-fer/RESNET50-WCW-AUX-BEST-72.4.h5\")\n",
    "Senet_Aux_model = load_model('/usr/users/gpupro/gprcsr1_1/Desktop/ST7_FER_Projet/cs230-fer/SENET50-AUX-BEST-72.5.h5')\n",
    "Senet_Aux_model_wcw = load_model('/usr/users/gpupro/gprcsr1_1/Desktop/ST7_FER_Projet/cs230-fer/SENET50-WCW-AUX-BEST-71.6.h5')\n",
    "VGG_Aux_model = load_model(\"/usr/users/gpupro/gprcsr1_1/Desktop/ST7_FER_Projet/cs230-fer/VGG16-AUX-BEST-70.2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_SOA = [model1, model2]\n",
    "models_TL = [Resnet_model, Resnet_Aux_model_wcw, Senet_Aux_model, Senet_Aux_model_wcw, VGG_Aux_model]\n",
    "\n",
    "models = [models_SOA, models_TL]\n",
    "#models_list = ['model1', 'model2', 'Resnet_model',' Resnet_Aux_model_wcw', 'Senet_Aux_model', 'Senet_Aux_model_wcw', 'VGG_Aux_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n','model 1' , '\\n', 'Evaluate on dev data')\n",
    "results_dev = model1.evaluate(X_res_dev,Y_dev)\n",
    "print('dev loss, dev acc:', results_dev)\n",
    "\n",
    "print('\\n Evaluate on test data')\n",
    "results_test = model1.evaluate(X_res_test,Y_test)\n",
    "print('test loss, test acc:', results_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n','model 2' , '\\n', 'Evaluate on dev data')\n",
    "results_dev = model2.evaluate(X_res_dev,Y_dev)\n",
    "print('dev loss, dev acc:', results_dev)\n",
    "\n",
    "print('\\n Evaluate on test data')\n",
    "results_test = model2.evaluate(X_res_test,Y_test)\n",
    "print('test loss, test acc:', results_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n','Resnet_model' , '\\n', 'Evaluate on dev data')\n",
    "results_dev = Resnet_model.evaluate(X_res_dev,Y_dev)\n",
    "print('dev loss, dev acc:', results_dev)\n",
    "\n",
    "print('\\n Evaluate on test data')\n",
    "results_test = Resnet_model.evaluate(X_res_test,Y_test)\n",
    "print('test loss, test acc:', results_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n','Resnet_Aux_model_wcw' , '\\n', 'Evaluate on dev data')\n",
    "results_dev = Resnet_Aux_model_wcw.evaluate(X_res_dev,Y_dev)\n",
    "print('dev loss, dev acc:', results_dev)\n",
    "\n",
    "print('\\n Evaluate on test data')\n",
    "results_test = Resnet_Aux_model_wcw.evaluate(X_res_test,Y_test)\n",
    "print('test loss, test acc:', results_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n','Senet_Aux_model' , '\\n', 'Evaluate on dev data')\n",
    "results_dev = Senet_Aux_model.evaluate(X_res_dev,Y_dev)\n",
    "print('dev loss, dev acc:', results_dev)\n",
    "\n",
    "print('\\n Evaluate on test data')\n",
    "results_test = Senet_Aux_model.evaluate(X_res_test,Y_test)\n",
    "print('test loss, test acc:', results_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n','Sesnet_Aux_model_wcw' , '\\n', 'Evaluate on dev data')\n",
    "results_dev = Sesnet_Aux_model_wcw.evaluate(X_res_dev,Y_dev)\n",
    "print('dev loss, dev acc:', results_dev)\n",
    "\n",
    "print('\\n Evaluate on test data')\n",
    "results_test = Sesnet_Aux_model_wcw.evaluate(X_res_test,Y_test)\n",
    "print('test loss, test acc:', results_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n','VGG_Aux_model' , '\\n', 'Evaluate on dev data')\n",
    "results_dev = VGG_Aux_model.evaluate(X_res_dev,Y_dev)\n",
    "print('dev loss, dev acc:', results_dev)\n",
    "\n",
    "print('\\n Evaluate on test data')\n",
    "results_test = VGG_Aux_model.evaluate(X_res_test,Y_test)\n",
    "print('test loss, test acc:', results_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an ensemble prediction for multi-class classification\n",
    "def ensemble_predictions(models_SOA, testX, models_TL, testresX):\n",
    "  # make predictions\n",
    "  yhats = np.zeros((len(models_SOA)+len(models_TL),testX.shape[0],7))\n",
    "\n",
    "  for model_ind in range(len(models_SOA)):\n",
    "    yhat = models_SOA[model_ind].predict(testX)\n",
    "    yhats[model_ind,:,:] = yhat\n",
    "\n",
    "  for model_ind in range(len(models_TL)):\n",
    "    yhat = models_TL[model_ind].predict(testresX)\n",
    "    yhats[len(models_SOA)+model_ind,:,:] = yhat\n",
    "\n",
    "  summed = np.sum(yhats, axis=0)\n",
    "  result = np.argmax(summed, axis=1)\n",
    "  return result\n",
    " \n",
    "# evaluate a specific number of members in an ensemble\n",
    "def evaluate_n_members(models_SOA, testX, models_TL, testresX, testy):\n",
    "    # select a subset of members\n",
    "    #subset = members[:n_members]\n",
    "    #print(len(subset))\n",
    "    # make prediction\n",
    "    yhat = ensemble_predictions(models_SOA, testX, models_TL, testresX)\n",
    "    # calculate accuracy\n",
    "    return accuracy_score(testy, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_acc = evaluate_n_members(models_SOA, X_test, models_TL, X_res_test, np.argmax(Y_test, axis=1))\n",
    "print(ens_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.3",
   "language": "python",
   "name": "ddsp0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
