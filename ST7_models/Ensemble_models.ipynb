{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "corresponding-defensive",
   "metadata": {},
   "source": [
    "# Ensemble Models\n",
    "\n",
    "We performed ensembling with soft voting of seven models to improve our highest test accuracy.\n",
    "\n",
    "The models can be downloaded from [Google Drive](https://drive.google.com/drive/folders/1F2isfUMEt7I6WH9LGIwc-IG-C2-9PWk4?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-casting",
   "metadata": {},
   "source": [
    "## Import Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-despite",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.python.lib.io import file_io\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import plot_model\n",
    "from sklearn.metrics import *\n",
    "from keras.engine import Model\n",
    "from keras.layers import Input, Flatten, Dense, Activation, Conv2D, MaxPool2D, BatchNormalization, Dropout, MaxPooling2D\n",
    "\n",
    "import skimage\n",
    "from skimage.transform import rescale, resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "print('Importing successfully!')\n",
    "print('tensorflow',tf.__version__)\n",
    "print('tensorflow.keras',tf.keras.__version__)\n",
    "print('keras',keras.__version__)\n",
    "print('GPU',tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-concord",
   "metadata": {},
   "source": [
    "## Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-yesterday",
   "metadata": {},
   "outputs": [],
   "source": [
    "Resize_pixelsize = 197\n",
    "\n",
    "# Function that reads the data from the csv file, increases the size of the images and returns the images and their labels\n",
    "def get_data(dataset_path, Resize_pixelsize = 197):\n",
    "    \n",
    "    file_stream = file_io.FileIO(dataset_path, mode='r')\n",
    "    data = pd.read_csv(file_stream)\n",
    "    data['pixels'] = data['pixels'].apply(lambda x: [int(pixel) for pixel in x.split()])\n",
    "    X, Y = data['pixels'].tolist(), data['emotion'].values\n",
    "    X = np.array(X, dtype='float32').reshape(-1,48,48,1)\n",
    "    X = X/255.0\n",
    "   \n",
    "    X_res = np.zeros((X.shape[0], Resize_pixelsize,Resize_pixelsize,3))\n",
    "    for ind in range(X.shape[0]): \n",
    "        sample = X[ind]\n",
    "        sample = sample.reshape(48, 48)\n",
    "        image_resized = resize(sample, (Resize_pixelsize, Resize_pixelsize), anti_aliasing=True)\n",
    "        X_res[ind,:,:,:] = image_resized.reshape(Resize_pixelsize,Resize_pixelsize,1)\n",
    "\n",
    "    Y_res = np.zeros((Y.size, 7))\n",
    "    Y_res[np.arange(Y.size),Y] = 1    \n",
    "    \n",
    "    return  X, X_res, Y_res\n",
    "\n",
    "dev_dataset_dir = '/Users/ouyang/Documents/GitHub/ST7_FER_Projet/FER_Dataset/csv/dev.csv'\n",
    "test_dataset_dir = '/Users/ouyang/Documents/GitHub/ST7_FER_Projet/FER_Dataset/csv/test.csv'\n",
    "\n",
    "print('Getting data. It may take a few minutes')\n",
    "X_dev, X_res_dev, Y_dev   = get_data(dev_dataset_dir)\n",
    "X_test, X_res_test, Y_test   = get_data(test_dataset_dir)\n",
    "print('Import dataset successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-tension",
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 128 # batch size,batch size = 128\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def get_datagen(dataset, BS = 128, aug=False):\n",
    "    if aug:\n",
    "        datagen = ImageDataGenerator(\n",
    "                            rescale=1./255,\n",
    "                            featurewise_center=False,\n",
    "                            featurewise_std_normalization=False,\n",
    "                            rotation_range=10,\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1,\n",
    "                            zoom_range=0.1,\n",
    "                            horizontal_flip=True)\n",
    "    else:\n",
    "        datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    return datagen.flow_from_directory(\n",
    "            dataset,\n",
    "            target_size=(48, 48),\n",
    "            color_mode='grayscale',\n",
    "            shuffle = True,\n",
    "            class_mode='categorical',\n",
    "            batch_size=BS)\n",
    "\n",
    "dev_generator    = get_datagen(\"/Users/ouyang/Documents/GitHub/ST7_FER_Projet/FER_Dataset/test-private\")\n",
    "test_generator  = get_datagen(\"/Users/ouyang/Documents/GitHub/ST7_FER_Projet/FER_Dataset/test-public\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-sister",
   "metadata": {},
   "source": [
    "## Import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-sound",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model('trained_models/Basic-EPOCHS_300-DROPOUT_0.3-test_acc_0.641.h5')\n",
    "model2 = load_model('trained_models/Basic-EPOCHS_350-DROPOUT_0.3-test_acc_0.646.h5')\n",
    "\n",
    "Resnet_model = load_model('trained_models/RESNET50-EPOCHS_100test_acc_0.716.h5')\n",
    "Resnet_Aux_model_wcw = load_model(\"cs230-fer/RESNET50-WCW-AUX-BEST-72.4.h5\")\n",
    "Senet_Aux_model = load_model('cs230-fer/SENET50-AUX-BEST-72.5.h5')\n",
    "Senet_Aux_model_wcw = load_model('cs230-fer/SENET50-WCW-AUX-BEST-71.6.h5')\n",
    "VGG_Aux_model = load_model(\"trained_models/VGG16-EPOCHS_50test_acc_0.701.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n', 'model 1', '\\n','Evaluate on dev data')\n",
    "results_dev = model1.evaluate(X_dev,Y_dev)\n",
    "print('dev loss, dev acc:', results_dev)\n",
    "\n",
    "print('\\n# Evaluate on test data')\n",
    "results_test = model1.evaluate(X_test,Y_test)\n",
    "print('test loss, test acc:', results_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-jackson",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n', 'model 2', '\\n','Evaluate on dev data')\n",
    "results_dev = model2.evaluate(X_dev,Y_dev)\n",
    "print('dev loss, dev acc:', results_dev)\n",
    "\n",
    "print('\\n# Evaluate on test data')\n",
    "results_test = model2.evaluate(X_test,Y_test)\n",
    "print('test loss, test acc:', results_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-seattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n','Resnet_model' , '\\n', 'Evaluate on dev data')\n",
    "results_dev = Resnet_model.evaluate(X_res_dev,Y_dev)\n",
    "print('dev loss, dev acc:', results_dev)\n",
    "\n",
    "print('\\n Evaluate on test data')\n",
    "results_test = Resnet_model.evaluate(X_res_test,Y_test)\n",
    "print('test loss, test acc:', results_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-genesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n','Resnet_Aux_model_wcw' , '\\n', 'Evaluate on dev data')\n",
    "results_dev = Resnet_Aux_model_wcw.evaluate(X_res_dev,Y_dev)\n",
    "print('dev loss, dev acc:', results_dev)\n",
    "\n",
    "print('\\n Evaluate on test data')\n",
    "results_test = Resnet_Aux_model_wcw.evaluate(X_res_test,Y_test)\n",
    "print('test loss, test acc:', results_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-guest",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n','Senet_Aux_model' , '\\n', 'Evaluate on dev data')\n",
    "results_dev = Senet_Aux_model.evaluate(X_res_dev,Y_dev)\n",
    "print('dev loss, dev acc:', results_dev)\n",
    "\n",
    "print('\\n Evaluate on test data')\n",
    "results_test = Senet_Aux_model.evaluate(X_res_test,Y_test)\n",
    "print('test loss, test acc:', results_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-soldier",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n','Senet_Aux_model_wcw' , '\\n', 'Evaluate on dev data')\n",
    "results_dev = Senet_Aux_model_wcw.evaluate(X_res_dev,Y_dev)\n",
    "print('dev loss, dev acc:', results_dev)\n",
    "\n",
    "print('\\n Evaluate on test data')\n",
    "results_test = Senet_Aux_model_wcw.evaluate(X_res_test,Y_test)\n",
    "print('test loss, test acc:', results_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-married",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n','VGG_Aux_model' , '\\n', 'Evaluate on dev data')\n",
    "results_dev = VGG_Aux_model.evaluate(X_res_dev,Y_dev)\n",
    "print('dev loss, dev acc:', results_dev)\n",
    "\n",
    "print('\\n Evaluate on test data')\n",
    "results_test = VGG_Aux_model.evaluate(X_res_test,Y_test)\n",
    "print('test loss, test acc:', results_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-chambers",
   "metadata": {},
   "source": [
    "## Ensemble models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-delhi",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_SOA = [model2]\n",
    "models_TL = [Resnet_model,Resnet_Aux_model_wcw, Senet_Aux_model, Senet_Aux_model_wcw, VGG_Aux_model] \n",
    "\n",
    "models = [models_SOA, models_TL]\n",
    "#models_list = ['model1', 'model2', 'Resnet_model',' Resnet_Aux_model_wcw', 'Senet_Aux_model', 'Senet_Aux_model_wcw', 'VGG_Aux_model']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-least",
   "metadata": {},
   "source": [
    "In soft voting, every individual classifier provides a probability value that a specific data point belongs to a particular target class. The predictions are weighted by the classifier's importance and summed up. Then the target label with the greatest sum of weighted probabilities wins the vote\n",
    "\n",
    "[sklearn.metrics.accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-bachelor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an ensemble prediction for multi-class classification\n",
    "def ensemble_predictions(models_SOA, testX, models_TL, testresX):\n",
    "  # make predictions\n",
    "  yhats = np.zeros((len(models_SOA)+len(models_TL),testX.shape[0],7))\n",
    "\n",
    "  for model_ind in range(len(models_SOA)):\n",
    "    yhat = models_SOA[model_ind].predict(testX)\n",
    "    yhats[model_ind,:,:] = yhat\n",
    "\n",
    "  for model_ind in range(len(models_TL)):\n",
    "    yhat = models_TL[model_ind].predict(testresX) # res = rescale\n",
    "    yhats[len(models_SOA)+model_ind,:,:] = yhat\n",
    "\n",
    "  summed = np.sum(yhats, axis=0)\n",
    "  result = np.argmax(summed, axis=1)\n",
    "  return result\n",
    " \n",
    "# evaluate a specific number of members in an ensemble\n",
    "def evaluate_n_members(models_SOA, testX, models_TL, testresX, testy):\n",
    "    # select a subset of members\n",
    "    #subset = members[:n_members]\n",
    "    #print(len(subset))\n",
    "    # make prediction\n",
    "    yhat = ensemble_predictions(models_SOA, testX, models_TL, testresX)\n",
    "    print(yhat)\n",
    "    # calculate accuracy\n",
    "    return accuracy_score(testy, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-landscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_acc = evaluate_n_members(models_SOA, X_test, models_TL, X_res_test, np.argmax(Y_test, axis=1))\n",
    "print(ens_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-profit",
   "metadata": {},
   "source": [
    "## Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-victoria",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load an color image in grayscale\n",
    "img = cv2.imread('/Users/ouyang/Documents/GitHub/ST7_FER_Projet/FER_Dataset/demo/0 anrgy/WechatIMG1773.jpeg', 0)\n",
    "print(np.shape(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-tucson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo(demo_path, models_SOA, models_TL, Resize_pixelsize = 197):\n",
    "    \n",
    "    file_stream = file_io.FileIO(dataset_path, mode='r')\n",
    "    data = pd.read_csv(file_stream)\n",
    "    data['pixels'] = data['pixels'].apply(lambda x: [int(pixel) for pixel in x.split()])\n",
    "    X, Y = data['pixels'].tolist(), data['emotion'].values\n",
    "    X = np.array(X, dtype='float32').reshape(-1,48,48,1)\n",
    "    X = X/255.0\n",
    "   \n",
    "    X_res = np.zeros((X.shape[0], Resize_pixelsize,Resize_pixelsize,3))\n",
    "    for ind in range(X.shape[0]): \n",
    "        sample = X[ind]\n",
    "        sample = sample.reshape(48, 48)\n",
    "        image_resized = resize(sample, (Resize_pixelsize, Resize_pixelsize), anti_aliasing=True)\n",
    "        X_res[ind,:,:,:] = image_resized.reshape(Resize_pixelsize,Resize_pixelsize,1)   \n",
    "    \n",
    "    return  ensemble_predictions(demo_path, models_SOA, X, models_TL, X_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-buyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(demo(demo_path, models_SOA, models_TL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-poverty",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = {0:'Angry', 1:'Disgust', 2:'Fear', 3:'Happy', 4:'Sad', 5:'Surprise', 6:'Neutral'}\n",
    "\n",
    "model = load_model(r'/Users/ouyang/Documents/GitHub/ST7_FER_Projet/ST7_FER_Github/ST7_models/cs230-fer/VGG16-AUX-BEST-70.2.h5') \n",
    "demo_generator  = get_datagen(r\"/Users/ouyang/Documents/GitHub/ST7_FER_Projet/FER_Dataset/demo\")\n",
    "\n",
    "# y_true = demo_generator.classes\n",
    "# print(y_true)\n",
    "y_pred = model.predict(demo_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-framework",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
