{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Models\n",
    "\n",
    "We performed ensembling with soft voting of seven models to significantly improve our highest test accuracy.\n",
    "\n",
    "[sklearn.ensemble.VotingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "clf1 = LogisticRegression(multi_class='multinomial', random_state=1)\n",
    "clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "y = np.array([1, 1, 1, 2, 2, 2])\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
    "eclf1 = eclf1.fit(X, y)\n",
    "print(eclf1.predict(X))\n",
    "\n",
    "np.array_equal(eclf1.named_estimators_.lr.predict(X),eclf1.named_estimators_['lr'].predict(X))\n",
    "\n",
    "eclf2 = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],voting='soft')\n",
    "eclf2 = eclf2.fit(X, y)\n",
    "print(eclf2.predict(X))\n",
    "\n",
    "eclf3 = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],voting='soft', weights=[2,1,1],flatten_transform=True)\n",
    "eclf3 = eclf3.fit(X, y)\n",
    "print(eclf3.predict(X))\n",
    "print(eclf3.transform(X).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.python.lib.io import file_io\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import plot_model\n",
    "from sklearn.metrics import *\n",
    "from keras.engine import Model\n",
    "from keras.layers import Input, Flatten, Dense, Activation, Conv2D, MaxPool2D, BatchNormalization, Dropout, MaxPooling2D\n",
    "\n",
    "import skimage\n",
    "from skimage.transform import rescale, resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Resize_pixelsize = 197"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that reads the data from the csv file, increases the size of the images and returns the images and their labels\n",
    "def get_data(dataset_patj):\n",
    "    \n",
    "    file_stream = file_io.FileIO(dataset_path, mode='r')\n",
    "    data = pd.read_csv(file_stream)\n",
    "    data[' pixels'] = data[' pixels'].apply(lambda x: [int(pixel) for pixel in x.split()])\n",
    "    X, Y = data[' pixels'].tolist(), data['emotion'].values\n",
    "    X = np.array(X, dtype='float32').reshape(-1,48,48,1)\n",
    "    X = X/255.0\n",
    "   \n",
    "    X_res = np.zeros((X.shape[0], Resize_pixelsize,Resize_pixelsize,3))\n",
    "    for ind in range(X.shape[0]): \n",
    "        sample = X[ind]\n",
    "        sample = sample.reshape(48, 48)\n",
    "        image_resized = resize(sample, (Resize_pixelsize, Resize_pixelsize), anti_aliasing=True)\n",
    "        X_res[ind,:,:,:] = image_resized.reshape(Resize_pixelsize,Resize_pixelsize,1)\n",
    "\n",
    "    Y_res = np.zeros((Y.size, 7))\n",
    "    Y_res[np.arange(Y.size),Y] = 1    \n",
    "    \n",
    "    return  X, X_res, Y_res\n",
    "\n",
    "dev_dataset_dir = '/content/drive/My Drive/cs230 project/collab/fer2013/dev.csv'\n",
    "test_dataset_dir = '/content/drive/My Drive/cs230 project/collab/fer2013/test.csv'\n",
    "\n",
    "X_dev, X_res_dev, Y_dev   = get_data(dev_dataset_dir)\n",
    "X_test, X_res_test, Y_test   = get_data(test_dataset_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model('/content/drive/My Drive/cs230 project/models/soa-SGD_LR_0.01000-EPOCHS_300-BS_128-DROPOUT_0.3test_acc_0.663.h5')\n",
    "model2 = load_model('/content/drive/My Drive/cs230 project/models/soa-SGD_LR_0.01000-EPOCHS_300-BS_128-DROPOUT_0.4test_acc_0.657.h5')\n",
    "\n",
    "Resnet_model = load_model('/content/drive/My Drive/cs230 project/models/tl/ResNet-BEST-73.2.h5')\n",
    "Resnet_model_wcw = load_model('/content/drive/My Drive/cs230 project/models/tl/ResNet-BEST-WCW-0.677.h5')\n",
    "Senet_model_wcw = load_model('/content/drive/My Drive/cs230 project/models/tl/SeNet50-WCW-BEST-68.9.h5')\n",
    "Resnet_Aux_model = load_model(\"/content/drive/My Drive/cs230 project/models/final/RESNET50-AUX-BEST-72.7.h5\")\n",
    "Resnet_Aux_model_wcw = load_model(\"/content/drive/My Drive/cs230 project/models/final/RESNET50-WCW-AUX-BEST-72.4.h5\")\n",
    "Senet_Aux_model = load_model('/content/drive/My Drive/cs230 project/models/final/SENET50-AUX-BEST-72.5.h5')\n",
    "Senet_Aux_model_wcw = load_model('/content/drive/My Drive/cs230 project/models/final/SENET50-WCW-AUX-BEST-71.6.h5')\n",
    "VGG_Aux_model = load_model(\"/content/drive/My Drive/cs230 project/models/final/VGG16-AUX-BEST-70.2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_SOA = [model1, model2]\n",
    "models_TL = [Resnet_model, Resnet_Aux_model_wcw, Senet_Aux_model, Senet_Aux_model_wcw, VGG_Aux_model]\n",
    "models = models_SOA + models_TL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    print('\\n Model',model)\n",
    "    print('\\n Evaluate on dev data')\n",
    "    results_dev = model.evaluate(X_res_dev,Y_dev)\n",
    "    print('dev loss, dev acc:', results_dev)\n",
    "\n",
    "    print('\\n Evaluate on test data')\n",
    "    results_test = model.evaluate(X_res_test,Y_test)\n",
    "    print('test loss, test acc:', results_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an ensemble prediction for multi-class classification\n",
    "def ensemble_predictions(models_SOA, testX, models_TL, testresX):\n",
    "  # make predictions\n",
    "  yhats = np.zeros((len(models_SOA)+len(models_TL),testX.shape[0],7))\n",
    "\n",
    "  for model_ind in range(len(models_SOA)):\n",
    "    yhat = models_SOA[model_ind].predict(testX)\n",
    "    yhats[model_ind,:,:] = yhat\n",
    "\n",
    "  for model_ind in range(len(models_TL)):\n",
    "    yhat = models_TL[model_ind].predict(testresX)\n",
    "    yhats[len(models_SOA)+model_ind,:,:] = yhat\n",
    "\n",
    "  summed = np.sum(yhats, axis=0)\n",
    "  result = np.argmax(summed, axis=1)\n",
    "  return result\n",
    " \n",
    "# evaluate a specific number of members in an ensemble\n",
    "def evaluate_n_members(models_SOA, testX, models_TL, testresX, testy):\n",
    "    # select a subset of members\n",
    "    #subset = members[:n_members]\n",
    "    #print(len(subset))\n",
    "    # make prediction\n",
    "    yhat = ensemble_predictions(models_SOA, testX, models_TL, testresX)\n",
    "    # calculate accuracy\n",
    "    return accuracy_score(testy, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_acc = evaluate_n_members(models_SOA, X_test, models_TL, X_res_test, np.argmax(Y_test, axis=1))\n",
    "print(ens_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.3",
   "language": "python",
   "name": "ddsp0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
