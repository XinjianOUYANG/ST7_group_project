{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Transfer Learning Method***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-vggface in c:\\anaconda\\lib\\site-packages (0.6)\n",
      "Requirement already satisfied: pyyaml in c:\\anaconda\\lib\\site-packages (from keras-vggface) (5.3.1)\n",
      "Requirement already satisfied: h5py in c:\\anaconda\\lib\\site-packages (from keras-vggface) (2.10.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\anaconda\\lib\\site-packages (from keras-vggface) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\anaconda\\lib\\site-packages (from keras-vggface) (1.18.5)\n",
      "Requirement already satisfied: keras in c:\\anaconda\\lib\\site-packages (from keras-vggface) (2.4.3)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\anaconda\\lib\\site-packages (from keras-vggface) (1.5.0)\n",
      "Requirement already satisfied: pillow in c:\\anaconda\\lib\\site-packages (from keras-vggface) (7.2.0)\n",
      "Requirement already satisfied: scikit-image in c:\\anaconda\\lib\\site-packages (0.16.2)\n",
      "Requirement already satisfied: pillow>=4.3.0 in c:\\anaconda\\lib\\site-packages (from scikit-image) (7.2.0)\n",
      "Requirement already satisfied: networkx>=2.0 in c:\\anaconda\\lib\\site-packages (from scikit-image) (2.4)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in c:\\anaconda\\lib\\site-packages (from scikit-image) (3.2.2)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in c:\\anaconda\\lib\\site-packages (from scikit-image) (1.1.1)\n",
      "Requirement already satisfied: imageio>=2.3.0 in c:\\anaconda\\lib\\site-packages (from scikit-image) (2.9.0)\n",
      "Requirement already satisfied: scipy>=0.19.0 in c:\\anaconda\\lib\\site-packages (from scikit-image) (1.5.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\anaconda\\lib\\site-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\anaconda\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\anaconda\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.11 in c:\\anaconda\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.18.5)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\anaconda\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\anaconda\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\anaconda\\lib\\site-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.15.0)\n",
      "Requirement already satisfied: pydot in c:\\anaconda\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\anaconda\\lib\\site-packages (from pydot) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-vggface\n",
    "!pip install scikit-image\n",
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras_applications in c:\\anaconda\\lib\\site-packages (1.0.8)\n",
      "Requirement already satisfied: h5py in c:\\anaconda\\lib\\site-packages (from keras_applications) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\anaconda\\lib\\site-packages (from keras_applications) (1.18.5)\n",
      "Requirement already satisfied: six in c:\\anaconda\\lib\\site-packages (from h5py->keras_applications) (1.15.0)\n",
      "Requirement already satisfied: keras_preprocessing in c:\\anaconda\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\anaconda\\lib\\site-packages (from keras_preprocessing) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\anaconda\\lib\\site-packages (from keras_preprocessing) (1.18.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras_applications\n",
    "!pip install keras_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.python.lib.io import file_io\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras.utils import plot_model\n",
    "from sklearn.metrics import *\n",
    "from keras.engine import Model\n",
    "from keras.layers import Input, Flatten, Dense, Activation, Conv2D, MaxPool2D, BatchNormalization, Dropout, MaxPooling2D\n",
    "import skimage\n",
    "from skimage.transform import rescale, resize\n",
    "\n",
    "import pydot\n",
    "\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n",
      "2.4.3\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BS = 128\n",
    "DROPOUT_RATE = 0.5\n",
    "FROZEN_LAYER_NUM = 201\n",
    "\n",
    "ADAM_LEARNING_RATE = 0.001\n",
    "SGD_LEARNING_RATE = 0.01\n",
    "SGD_DECAY = 0.0001\n",
    "#stochastic gradient descent\n",
    "Resize_pixelsize = 197"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_notop = VGGFace(model='senet50', include_top=False, input_shape=(Resize_pixelsize, Resize_pixelsize, 3), pooling='avg')\n",
    "last_layer = vgg_notop.get_layer('avg_pool').output\n",
    "x = Flatten(name='flatten')(last_layer)\n",
    "x = Dropout(DROPOUT_RATE)(x) ## dropout prevent overfitting in neural network\n",
    "x = Dense(4096, activation='relu', name='fc6')(x)\n",
    "x = Dropout(DROPOUT_RATE)(x)\n",
    "x = Dense(1024, activation='relu', name='fc7')(x)\n",
    "x = Dropout(DROPOUT_RATE)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_norm_indices = [2, 6, 9, 12, 21, 25, 28, 31, 42, 45, 48, 59, 62, 65, 74, 78, 81, 84, 95, 98, 101, 112, 115, 118, 129, 132, 135, 144, 148, 151, 154, 165, 168, 171, 182, 185, 188, 199, 202, 205, 216, 219, 222, 233, 236, 239, 248, 252, 255, 258, 269, 272, 275]    \n",
    "for i in range(FROZEN_LAYER_NUM):\n",
    "    if i not in batch_norm_indices:\n",
    "        vgg_notop.layers[i].trainable = False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = Dense(7, activation='softmax', name='classifier')(x)\n",
    "\n",
    "model = Model(vgg_notop.input, out)\n",
    "\n",
    "optim = keras.optimizers.Adam(lr=ADAM_LEARNING_RATE, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "#optim = keras.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "sgd = keras.optimizers.SGD(lr=SGD_LEARNING_RATE, momentum=0.9, decay=SGD_DECAY, nesterov=True)\n",
    "rlrop = keras.callbacks.ReduceLROnPlateau(monitor='val_acc',mode='max',factor=0.5, patience=10, min_lr=0.00001, verbose=1) \n",
    "#ReduceLROnPlateau回调函数， 训练过程种优化学习率\n",
    "\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decompressing Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_file(zip_src, dst_dir):\n",
    "    r = zipfile.is_zipfile(zip_src)\n",
    "    if r:     \n",
    "        fz = zipfile.ZipFile(zip_src, 'r')\n",
    "        for file in fz.namelist():\n",
    "            fz.extract(file, dst_dir)       \n",
    "    else:\n",
    "        print('This is not zip')\n",
    "        \n",
    "        \n",
    "        \n",
    "## zip_src refers to the complete path of the zip file; and dst_dir refers to the directory in where you want to put the unzipped files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "unzip_file(r'C:\\Users\\59606\\Desktop\\train.zip',r'C:\\Users\\59606\\Desktop\\FER_Data\\train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "unzip_file(r'C:\\Users\\59606\\Desktop\\test-public.zip',r'C:\\Users\\59606\\Desktop\\FER_Data\\dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "unzip_file(r'C:\\Users\\59606\\Desktop\\test-private.zip',r'C:\\Users\\59606\\Desktop\\FER_Data\\test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the imagedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def get_datagen(dataset, aug=False):\n",
    "    if aug:\n",
    "        datagen = ImageDataGenerator(\n",
    "                            rescale=1./255,\n",
    "                            featurewise_center=False,\n",
    "                            featurewise_std_normalization=False,\n",
    "                            rotation_range=10,\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1,\n",
    "                            zoom_range=0.1,\n",
    "                            horizontal_flip=True)\n",
    "    else:\n",
    "        datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    return datagen.flow_from_directory(\n",
    "            dataset,\n",
    "            target_size=(197, 197),\n",
    "            color_mode='rgb',\n",
    "            shuffle = True,\n",
    "            class_mode='categorical',\n",
    "            batch_size=BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator  = get_datagen(r'C:\\Users\\59606\\Desktop\\FER_Data\\train', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3589 images belonging to 7 classes.\n",
      "Found 3589 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "dev_generator    = get_datagen(r'C:\\Users\\59606\\Desktop\\FER_Data\\dev')\n",
    "test_generator  = get_datagen(r'C:\\Users\\59606\\Desktop\\FER_Data\\test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-73:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Anaconda\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\data_utils.py\", line 748, in _run\n",
      "    with closing(self.executor_fn(_SHARED_SEQUENCES)) as executor:\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\data_utils.py\", line 725, in pool_fn\n",
      "    pool = get_pool_class(True)(\n",
      "  File \"C:\\Anaconda\\lib\\multiprocessing\\context.py\", line 119, in Pool\n",
      "    return Pool(processes, initializer, initargs, maxtasksperchild,\n",
      "  File \"C:\\Anaconda\\lib\\multiprocessing\\pool.py\", line 212, in __init__\n",
      "    self._repopulate_pool()\n",
      "  File \"C:\\Anaconda\\lib\\multiprocessing\\pool.py\", line 303, in _repopulate_pool\n",
      "    return self._repopulate_pool_static(self._ctx, self.Process,\n",
      "  File \"C:\\Anaconda\\lib\\multiprocessing\\pool.py\", line 326, in _repopulate_pool_static\n",
      "    w.start()\n",
      "  File \"C:\\Anaconda\\lib\\multiprocessing\\process.py\", line 121, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"C:\\Anaconda\\lib\\multiprocessing\\context.py\", line 326, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"C:\\Anaconda\\lib\\multiprocessing\\popen_spawn_win32.py\", line 93, in __init__\n",
      "    reduction.dump(process_obj, to_child)\n",
      "  File \"C:\\Anaconda\\lib\\multiprocessing\\reduction.py\", line 60, in dump\n",
      "    ForkingPickler(file, protocol).dump(obj)\n",
      "TypeError: cannot pickle '_thread.lock' object\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    generator = train_generator,\n",
    "    validation_data=dev_generator, \n",
    "    #steps_per_epoch=28709// BS,\n",
    "    #validation_steps=3509 // BS,\n",
    "    shuffle=True,\n",
    "    epochs=2,\n",
    "    callbacks=[rlrop],\n",
    "    use_multiprocessing=True,\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n# Evaluate on dev data')\n",
    "results_dev = model.evaluate_generator(dev_generator, 3509 // BS)\n",
    "print('dev loss, dev acc:', results_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n# Evaluate on test data')\n",
    "results_test = model.evaluate_generator(test_generator, 3509 // BS)\n",
    "print('test loss, test acc:', results_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'dev'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'dev'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_str = '-EPOCHS_' + str(EPOCHS)\n",
    "test_acc = 'test_acc_%.3f' % results_test[1]\n",
    "model.save('C:\\Users\\59606\\Desktop\\FER_Data\\model\\' + 'SENET50' + epoch_str + test_acc + '.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
